{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# NYC Taxi Route Analysis with PySpark & BigQuery\n",
        "## Comprehensive Route Speed & Efficiency Analysis\n",
        "\n",
        "This notebook performs advanced route analysis on NYC taxi data using PySpark and BigQuery integration.\n",
        "Based on 60+ million trip records, we'll analyze:\n",
        "- **Fastest routes between zones** (Section 6.2 implementation)\n",
        "- **Time-based route optimization**\n",
        "- **Driver efficiency analysis**\n",
        "- **Payment pattern correlations**\n",
        "\n",
        "Similar to Kaggle EDA notebooks but leveraging PySpark for big data processing.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql.window import Window\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "# Initialize Spark Session with BigQuery connector\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"NYC_Route_Analysis\") \\\n",
        "    .config(\"spark.jars.packages\", \"com.google.cloud.spark:spark-bigquery-with-dependencies_2.12:0.32.0\") \\\n",
        "    .config(\"spark.sql.adaptive.enabled\", \"true\") \\\n",
        "    .config(\"spark.sql.adaptive.coalescePartitions.enabled\", \"true\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# Set your GCP project\n",
        "PROJECT_ID = \"dtc-de-course-457315\"\n",
        "DATASET_ID = \"nyc_taxi_data\"\n",
        "\n",
        "print(f\"Spark Version: {spark.version}\")\n",
        "print(f\"Analyzing data from: {PROJECT_ID}.{DATASET_ID}\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 1. Data Loading & Preprocessing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load taxi trip data from BigQuery\n",
        "yellow_taxi_df = spark.read \\\n",
        "    .format(\"bigquery\") \\\n",
        "    .option(\"table\", f\"{PROJECT_ID}.{DATASET_ID}.yellow_taxi_external_table\") \\\n",
        "    .load()\n",
        "\n",
        "# Load zone lookup data\n",
        "zone_df = spark.read \\\n",
        "    .format(\"bigquery\") \\\n",
        "    .option(\"table\", f\"{PROJECT_ID}.{DATASET_ID}.taxi_zone_external_table\") \\\n",
        "    .load()\n",
        "\n",
        "print(f\"Yellow Taxi Records: {yellow_taxi_df.count():,}\")\n",
        "print(f\"Zone Records: {zone_df.count():,}\")\n",
        "\n",
        "# Clean and preprocess the data\n",
        "cleaned_trips = yellow_taxi_df \\\n",
        "    .filter(\n",
        "        (col(\"trip_distance\") > 0) & \n",
        "        (col(\"trip_distance\") < 100) &  # Remove unrealistic distances\n",
        "        (col(\"tpep_pickup_datetime\") < col(\"tpep_dropoff_datetime\")) &\n",
        "        (col(\"fare_amount\") > 0) &\n",
        "        (col(\"PULocationID\").isNotNull()) &\n",
        "        (col(\"DOLocationID\").isNotNull())\n",
        "    ) \\\n",
        "    .withColumn(\n",
        "        \"trip_duration_minutes\", \n",
        "        (unix_timestamp(col(\"tpep_dropoff_datetime\")) - unix_timestamp(col(\"tpep_pickup_datetime\"))) / 60\n",
        "    ) \\\n",
        "    .filter(\n",
        "        (col(\"trip_duration_minutes\") >= 1) & \n",
        "        (col(\"trip_duration_minutes\") <= 120)  # 1 min to 2 hours\n",
        "    ) \\\n",
        "    .withColumn(\n",
        "        \"avg_speed_mph\",\n",
        "        col(\"trip_distance\") / (col(\"trip_duration_minutes\") / 60)\n",
        "    ) \\\n",
        "    .filter(col(\"avg_speed_mph\") <= 80)  # Remove unrealistic speeds\n",
        "\n",
        "print(f\"Cleaned Records: {cleaned_trips.count():,}\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 2. Section 6.2 - Fastest Routes Analysis\n",
        "### (PySpark Implementation of Kaggle Notebook Section 6.2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Join with zone data to get location names\n",
        "pickup_zones = zone_df.select(\n",
        "    col(\"LocationID\").alias(\"pickup_zone_id\"),\n",
        "    col(\"Zone\").alias(\"pickup_zone_name\"),\n",
        "    col(\"Borough\").alias(\"pickup_borough\")\n",
        ")\n",
        "\n",
        "dropoff_zones = zone_df.select(\n",
        "    col(\"LocationID\").alias(\"dropoff_zone_id\"),\n",
        "    col(\"Zone\").alias(\"dropoff_zone_name\"),\n",
        "    col(\"Borough\").alias(\"dropoff_borough\")\n",
        ")\n",
        "\n",
        "# Create comprehensive route analysis with zone information\n",
        "route_analysis = cleaned_trips \\\n",
        "    .join(pickup_zones, col(\"PULocationID\") == col(\"pickup_zone_id\"), \"left\") \\\n",
        "    .join(dropoff_zones, col(\"DOLocationID\") == col(\"dropoff_zone_id\"), \"left\") \\\n",
        "    .withColumn(\"pickup_hour\", hour(col(\"tpep_pickup_datetime\"))) \\\n",
        "    .withColumn(\"day_of_week\", dayofweek(col(\"tpep_pickup_datetime\"))) \\\n",
        "    .withColumn(\"route_id\", concat(col(\"PULocationID\"), lit(\"-\"), col(\"DOLocationID\"))) \\\n",
        "    .withColumn(\"route_description\", concat(col(\"pickup_zone_name\"), lit(\" â†’ \"), col(\"dropoff_zone_name\")))\n",
        "\n",
        "route_analysis.cache()  # Cache for multiple operations\n",
        "print(\"Route analysis dataset created and cached\")\n",
        "\n",
        "# ===============================\n",
        "# CORE SECTION 6.2 ANALYSIS: FASTEST ROUTES\n",
        "# ===============================\n",
        "\n",
        "# Aggregate route statistics (similar to typical Kaggle analysis)\n",
        "route_stats = route_analysis.groupBy(\n",
        "    \"route_id\", \"pickup_zone_name\", \"dropoff_zone_name\", \n",
        "    \"pickup_borough\", \"dropoff_borough\", \"route_description\"\n",
        ").agg(\n",
        "    count(\"*\").alias(\"trip_count\"),\n",
        "    avg(\"trip_duration_minutes\").alias(\"avg_duration_minutes\"),\n",
        "    min(\"trip_duration_minutes\").alias(\"fastest_duration_minutes\"),\n",
        "    avg(\"avg_speed_mph\").alias(\"avg_speed_mph\"),\n",
        "    max(\"avg_speed_mph\").alias(\"max_speed_mph\"),\n",
        "    avg(\"trip_distance\").alias(\"avg_distance_miles\"),\n",
        "    avg(\"fare_amount\").alias(\"avg_fare\"),\n",
        "    stddev(\"avg_speed_mph\").alias(\"speed_std_dev\")\n",
        ").filter(col(\"trip_count\") >= 100)  # Ensure statistical significance\n",
        "\n",
        "print(f\"Route combinations with 100+ trips: {route_stats.count():,}\")\n",
        "\n",
        "# Find fastest routes by average speed\n",
        "fastest_routes_by_speed = route_stats.orderBy(col(\"avg_speed_mph\").desc()).limit(20)\n",
        "\n",
        "print(\"\\nðŸš€ TOP 20 FASTEST ROUTES BY AVERAGE SPEED:\")\n",
        "fastest_routes_by_speed.select(\n",
        "    \"route_description\", \n",
        "    round(\"avg_speed_mph\", 2).alias(\"avg_speed_mph\"), \n",
        "    round(\"avg_duration_minutes\", 2).alias(\"avg_duration_min\"), \n",
        "    round(\"avg_distance_miles\", 2).alias(\"avg_distance_mi\"), \n",
        "    \"trip_count\"\n",
        ").show(20, truncate=False)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
